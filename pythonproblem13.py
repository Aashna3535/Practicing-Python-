# -*- coding: utf-8 -*-
"""PythonProblem13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gATO6y86FPK796GPK_hX6WcznR0S4S2Y

Problem 13: Do word count with multi-threading. Create one class WordCount and initialize thread with list of file path. You have to ask user for number of thread and execute thread. At the end combine word count and write it in file.
Take input from user.  
Solution:
"""

# import OS module
import os

# Get the list of all files and directories
path = "/content/sampletxts"
dir_list = os.listdir(path)
  
print("Files and directories in '", path, "' :")
  
# prints all files
print(dir_list)

#Function which will remove punctuation and convert the text into lowercase
def remove_punctuation(text):
  punctuations = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''

   # remove punctuation from the text
  no_punct = ""
  for char in text:
     if char not in punctuations:
         no_punct = no_punct + char

  no_punct = no_punct.lower()
  # return the unpunctuated string
  return(no_punct)

#Importing file of NLTK's stopwords
from google.colab import files
uploaded = files.upload()

#Reading NLTK's stopwords file
with open('NLTK\'s list of english stopwords', 'r') as readfile:
    stopw = readfile.read()
print(stopw)

#Importing threading module
import threading
temp = ""

#Creating wordcount class 
class wordcount:
  #Defining function f which will do the word count of specified file path
  def f(self,x):
    global temp
  
    filtered_sentence=[]
    text = open(path + '/' + dir_list[x] , "rt")
    d = dict()
  
    # Loop through each line of the file
    for line in text:
      # Remove the leading spaces and newline character
      line = line.strip()
  
      # Calling function
      line = remove_punctuation(line)
  
      # Split the line into words
      words = line.split(" ")
    
      # Iterate over each word in line
      for word in words:

        if word not in stopw:#set(stopwords.words('english')): 
          filtered_sentence.append(word)
      
      for word in filtered_sentence:

        # Check if the word is already in dictionary
        if word in d:
          # Increment count of word by 1
          d[word] = d[word] + 1
        else:
          # Add the word to dictionary with count 1
          d[word] = 1
  
        #adding dictionary keys and values to string 
    for key in list(d.keys()):
      temp = temp + key + "," + str(d[key]) + '\n'

    temp = temp + "\n\n\n\n"  
    print("thread:",x,"\n")

#Taking user input for number of threads
x = int(input("Enter number of threads:"))

#Creating class object
wordcountobj = wordcount()
#Creating threads
for i in range(x):
  t = threading.Thread(target = wordcountobj.f, args=(i,))
  #Starting threads
  t.start()
  #Wait for all threads to complete
  t.join()

#writing a new file with a string which is having all file's words and its occurance counts    
with open('/content/Empty.txt', 'w') as writefile:
  writefile.write(temp)

#Reading that new file having words and their occurances of all files without punctuations
with open('/content/Empty.txt', 'r') as readfile:
    print(readfile.read())

