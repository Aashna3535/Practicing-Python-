# -*- coding: utf-8 -*-
"""PythonProblem8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aGe30yjvxoCmx08hi7ot3RCjz6uMHSpw

Problem 8: To get only top 10 terms based on frequency. Write those terms in new file in descending order   
Solution:
"""

#importing nltk library  
import nltk  
# import OS module
import os

from collections import Counter
  
nltk.download('stopwords') 
  
from nltk.corpus import stopwords 
print(stopwords.words('english'))

# Get the list of all files and directories
path = "/content/sampletxts"
dir_list = os.listdir(path)
  
print("Files and directories in '", path, "' :")
  
# prints all files
print(dir_list)

#Total number of word counts of every file
for x in dir_list:
  file = open(path + '/' + x , "rt")
  data = file.read()
  words = data.split()
  print('Number of total words in ' + x + ':', len(words))

#Function which will remove punctuation and convert the text into lowercase
def remove_punctuation(text):
  punctuations = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''

   # remove punctuation from the text
  no_punct = ""
  for char in text:
     if char not in punctuations:
         no_punct = no_punct + char

  no_punct = no_punct.lower()
  # return the unpunctuated string
  return(no_punct)

temp = ""
filtered_sentence=[]
#Loop through every file in a directory
for x in dir_list:
  text = open(path + '/' + x , "rt")
  d = dict()
  
  # Loop through each line of the file
  for line in text:
    # Remove the leading spaces and newline character
    line = line.strip()
  
    # Calling function
    line = remove_punctuation(line)
  
    # Split the line into words
    words = line.split(" ")
    
    # Iterate over each word in line
    for word in words:
      if word not in set(stopwords.words('english')): 
        filtered_sentence.append(word)
      
Counter = Counter(filtered_sentence)
most_occur = Counter.most_common(10)
  
print(most_occur)

type(most_occur[0][0])

temp = ""
#Converting list of most frequent words into string
for i in range(0,len(most_occur)):
  for j in range(0,2):
    temp = temp + str(most_occur[i][j]) + "," 
  temp = temp + "\n"
print(temp)

#passing that string to a new file     
with open('/content/Empty.txt', 'w') as writefile:
    writefile.writelines(temp)

#Reading that new file having most frequent words and their occurances of all files without punctuations
with open('/content/Empty.txt', 'r') as readfile:
    print(readfile.read())

